{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "d3m9h6quo3ru",
    "ExecuteTime": {
     "end_time": "2025-11-11T23:49:14.697044Z",
     "start_time": "2025-11-11T23:49:14.691838Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as pyplot\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "#**Assignment 2: Convolutional Neural Network**"
   ],
   "metadata": {
    "id": "z7JOpP8_J-Gs"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHJSkxJLo3ry"
   },
   "source": [
    "##**Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data: CIFAR-10\n",
    "\n",
    "CIFAR-10  is an established computer-vision dataset used for object recognition. It is a subset of the 80 million tiny images dataset and consists of 60,000 32x32 **color images** containing one of 10 object classes, with 6000 images per class.\n",
    "\n",
    "Labels are as follows:\n",
    "\n",
    "airplane (0), automobile (1), bird (2), cat (3), deer (4), dog (5), frog (6), horse (7), ship (8), truck (9)\n",
    "\n",
    "Source: https://www.kaggle.com/c/cifar-10"
   ],
   "metadata": {
    "id": "UXJY6A5YnJKv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q1. This dataset has been included in **keras.datasets.cifar10**. Please load the dataset and print the shape of training and testing sets."
   ],
   "metadata": {
    "id": "l2cPjB04KNLT"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MyOWqtGoo3ry",
    "outputId": "207b51e8-d8a6-4bec-8e2c-92c6b795d639",
    "ExecuteTime": {
     "end_time": "2025-11-11T23:49:15.547331Z",
     "start_time": "2025-11-11T23:49:14.718639Z"
    }
   },
   "source": [
    "# load CIFAR-10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "# print the shape of training and testing sets\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (50000, 32, 32, 3)\n",
      "Testing set shape: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q2. Convert the target labels (y) into the one-hot format and show the value (y) for the first instance of the training dataset."
   ],
   "metadata": {
    "id": "bDizbAGvKYnD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# convert target labels to one-hot format\n",
    "y_train_one_hot = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test_one_hot = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "# show the value for the first instance of the training dataset\n",
    "print(\"First instance of training labels (one-hot):\", y_train_one_hot[0])"
   ],
   "metadata": {
    "id": "M18oVvh9ySKO",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5d7ef23f-768f-4b72-abd2-184a7fcbe51d",
    "ExecuteTime": {
     "end_time": "2025-11-11T23:49:15.565015Z",
     "start_time": "2025-11-11T23:49:15.558671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First instance of training labels (one-hot): [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q3. Create a validation dataset using the first 5,000 instances in the training dataset. Also, divide all input features (X values) in the train/test/validation sets by 255.0. Please show the y value for the first instance of the validation dataset."
   ],
   "metadata": {
    "id": "irlvw6gdKdk7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# create validation dataset\n",
    "X_val = X_train[:5000] / 255.0\n",
    "y_val = y_train_one_hot[:5000]\n",
    "X_train = X_train[5000:] / 255.0\n",
    "y_train_one_hot = y_train_one_hot[5000:]\n",
    "X_test = X_test / 255.0\n",
    "# show the y value for the first instance of the validation dataset\n",
    "print(\"First instance of validation labels (one-hot):\", y_val[0])"
   ],
   "metadata": {
    "id": "m13RsiU4yGbL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b4657faa-b733-4635-92b5-9cead0cc2cea",
    "ExecuteTime": {
     "end_time": "2025-11-11T23:49:15.957260Z",
     "start_time": "2025-11-11T23:49:15.575058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First instance of validation labels (one-hot): [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fuCs0UYo3r2"
   },
   "source": [
    "## **Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q4. Create a convolutional neural network with 32 kernels of size 3 by 3 in the first layer and 64 kernels of size 3 by 3 in the second layer. We need a max pooling layer wth the size of 2 after each convolution layer. After flattening the feature maps add a fully-connected layer with 128 nodes for the final prediction. Please print the model summary.\n",
    "\n",
    "### Please note that the input images are color images with the shape of **32 * 32 * 3**. Here 3 shows RGB."
   ],
   "metadata": {
    "id": "s2BVGeGeKw3q"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8IcXIoco3r3",
    "outputId": "7e2a87b9-c60b-476f-c787-a6b30caad945",
    "ExecuteTime": {
     "end_time": "2025-11-11T23:49:16.136777Z",
     "start_time": "2025-11-11T23:49:15.975002Z"
    }
   },
   "source": [
    "# create the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3),padding='same'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu',padding='same'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "# print the model summary\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_7\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_14 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │           \u001B[38;5;34m896\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (\u001B[38;5;33mMaxPooling2D\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │        \u001B[38;5;34m18,496\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_15 (\u001B[38;5;33mMaxPooling2D\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m64\u001B[0m)       │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (\u001B[38;5;33mFlatten\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4096\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │       \u001B[38;5;34m524,416\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │         \u001B[38;5;34m1,290\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m545,098\u001B[0m (2.08 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">545,098</span> (2.08 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m545,098\u001B[0m (2.08 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">545,098</span> (2.08 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q5. Create an Adam optimizer with a learning rate of 0.001, compile the model, and fit it on the training and validation datasets. Use the following hyperparameters: **batch_size=512, epochs=5**.\n",
    "\n",
    "### *Hint*: Adam optimizer can be imported by **keras.optimizers.Adam(learning_rate=0.001)**"
   ],
   "metadata": {
    "id": "KmWoV95YMCNk"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6BKgqfiPo3r3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "15a896d1-d95c-4c58-cba5-d271c96ccbd6",
    "ExecuteTime": {
     "end_time": "2025-11-11T23:50:06.360719Z",
     "start_time": "2025-11-11T23:49:16.159532Z"
    }
   },
   "source": [
    "# create Adam optimizer\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "# compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# fit the model\n",
    "model.fit(X_train, y_train_one_hot,\n",
    "          batch_size=512,\n",
    "          epochs=5,\n",
    "          validation_data=(X_val, y_val))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m88/88\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 106ms/step - accuracy: 0.3795 - loss: 1.7355 - val_accuracy: 0.4976 - val_loss: 1.4435\n",
      "Epoch 2/5\n",
      "\u001B[1m88/88\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 108ms/step - accuracy: 0.5117 - loss: 1.3787 - val_accuracy: 0.5548 - val_loss: 1.2678\n",
      "Epoch 3/5\n",
      "\u001B[1m88/88\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 109ms/step - accuracy: 0.5743 - loss: 1.2233 - val_accuracy: 0.5828 - val_loss: 1.1764\n",
      "Epoch 4/5\n",
      "\u001B[1m88/88\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 114ms/step - accuracy: 0.6073 - loss: 1.1315 - val_accuracy: 0.6138 - val_loss: 1.1217\n",
      "Epoch 5/5\n",
      "\u001B[1m88/88\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 115ms/step - accuracy: 0.6292 - loss: 1.0637 - val_accuracy: 0.6188 - val_loss: 1.0733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1486106a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgASb27Yo3r4"
   },
   "source": [
    "## **Performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q6. Evaluate your model."
   ],
   "metadata": {
    "id": "EMO1uaTuMX6d"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fHNLT-6Io3r4",
    "outputId": "14dc514b-08fe-459e-a7f6-c1497c35dd4c",
    "ExecuteTime": {
     "end_time": "2025-11-11T23:50:07.420039Z",
     "start_time": "2025-11-11T23:50:06.374993Z"
    }
   },
   "source": [
    "# evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_one_hot)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.6201 - loss: 1.0761\n",
      "Test accuracy: 0.6201000213623047\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Post-analysis**"
   ],
   "metadata": {
    "id": "uARsdLky1CR9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q7. Print the name of layers.\n",
    "\n",
    "#### Note: You may choose any name you like for your layers."
   ],
   "metadata": {
    "id": "LUbdfQ3eMdX-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# print the name of layers\n",
    "for layer in model.layers:\n",
    "    print(layer.name)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kS543ElY7OAO",
    "outputId": "bf09dc2e-2030-4e4e-a8b4-2e050ba66724",
    "ExecuteTime": {
     "end_time": "2025-11-11T23:50:07.438048Z",
     "start_time": "2025-11-11T23:50:07.435469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_14\n",
      "max_pooling2d_14\n",
      "conv2d_15\n",
      "max_pooling2d_15\n",
      "flatten_7\n",
      "dense_14\n",
      "dense_15\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q8. Print the output of layers."
   ],
   "metadata": {
    "id": "iClOesXnNU0e"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Ensure the model is built by calling it with a dummy input\n",
    "dummy_input = tf.zeros((1, 32, 32, 3))  # Shape matches the input shape of the model\n",
    "model(dummy_input)\n",
    "\n",
    "# Create a new model that outputs the intermediate layers\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = keras.Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "# Get the outputs for the first test instance\n",
    "activations = activation_model(X_test[4:5])\n",
    "\n",
    "# Print the output of each layer\n",
    "for i, activation in enumerate(activations):\n",
    "    print(f\"Output of layer {i} ({model.layers[i].name}):\")\n",
    "    print(activation.numpy())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EZNFhnUS7Rbv",
    "outputId": "71e03a97-0bda-49ba-9e20-ef4b4d3cee25",
    "ExecuteTime": {
     "end_time": "2025-11-11T23:53:34.830369Z",
     "start_time": "2025-11-11T23:53:34.300756Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The layer sequential_7 has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[37], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Create a new model that outputs the intermediate layers\u001B[39;00m\n\u001B[1;32m      6\u001B[0m layer_outputs \u001B[38;5;241m=\u001B[39m [layer\u001B[38;5;241m.\u001B[39moutput \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers]\n\u001B[0;32m----> 7\u001B[0m activation_model \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mModel(inputs\u001B[38;5;241m=\u001B[39m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput\u001B[49m, outputs\u001B[38;5;241m=\u001B[39mlayer_outputs)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Get the outputs for the first test instance\u001B[39;00m\n\u001B[1;32m     10\u001B[0m activations \u001B[38;5;241m=\u001B[39m activation_model(X_test[\u001B[38;5;241m4\u001B[39m:\u001B[38;5;241m5\u001B[39m])\n",
      "File \u001B[0;32m~/PycharmProjects/ISBA_2414/.venv/lib/python3.10/site-packages/keras/src/ops/operation.py:275\u001B[0m, in \u001B[0;36mOperation.input\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21minput\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    267\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001B[39;00m\n\u001B[1;32m    268\u001B[0m \n\u001B[1;32m    269\u001B[0m \u001B[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    273\u001B[0m \u001B[38;5;124;03m        Input tensor or list of input tensors.\u001B[39;00m\n\u001B[1;32m    274\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 275\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_node_attribute_at_index\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput_tensors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ISBA_2414/.venv/lib/python3.10/site-packages/keras/src/ops/operation.py:306\u001B[0m, in \u001B[0;36mOperation._get_node_attribute_at_index\u001B[0;34m(self, node_index, attr, attr_name)\u001B[0m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001B[39;00m\n\u001B[1;32m    291\u001B[0m \n\u001B[1;32m    292\u001B[0m \u001B[38;5;124;03mThis is used to implement the properties:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    303\u001B[0m \u001B[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001B[39;00m\n\u001B[1;32m    304\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inbound_nodes:\n\u001B[0;32m--> 306\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[1;32m    307\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe layer \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m has never been called \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mand thus has no defined \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    309\u001B[0m     )\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inbound_nodes) \u001B[38;5;241m>\u001B[39m node_index:\n\u001B[1;32m    311\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    312\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsked to get \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m at node \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    313\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnode_index\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, but the operation has only \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    314\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inbound_nodes)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m inbound nodes.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    315\u001B[0m     )\n",
      "\u001B[0;31mAttributeError\u001B[0m: The layer sequential_7 has never been called and thus has no defined input."
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q9. Print the output shape of feature maps in the convolution layers as well as the pooling layers for the fifth instance in your test dataset."
   ],
   "metadata": {
    "id": "IToewQGHNeOV"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bZqf3qD7Uue",
    "outputId": "79dd8b0a-4ca5-43f9-f197-e0682565d240",
    "ExecuteTime": {
     "end_time": "2025-11-11T23:50:07.561344Z",
     "start_time": "2025-11-11T23:47:15.473243Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The frog image below should be your fifth testing instance (index=4)."
   ],
   "metadata": {
    "id": "rPpDAX6kN_6u"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "id": "ZpxYD2_t7fn3",
    "outputId": "ec071ccf-3b8e-40ac-c190-c85f3af5b15d",
    "ExecuteTime": {
     "end_time": "2025-11-11T23:50:07.562476Z",
     "start_time": "2025-11-11T23:47:15.485674Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q10. Draw 16 feature maps for each convolution and pooling layer."
   ],
   "metadata": {
    "id": "HXvbOtLmOQbm"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "peVqcQpR77Dw",
    "outputId": "a9d335fb-c662-4b54-8335-e167a4af8706",
    "ExecuteTime": {
     "end_time": "2025-11-11T23:50:07.563468Z",
     "start_time": "2025-11-11T23:47:15.497201Z"
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
